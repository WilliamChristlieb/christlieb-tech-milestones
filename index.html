<!DOCTYPE html>

<html>
    <head>

<meta charset="UTF-8">

<meta name="description" content="research on key milestones in the development of computers and logical devices">

<meta name="keywords" content="milestones,coding,computers,Dev Catalyst,project">

<meta name="author" content="William Christlieb">

<title>Christlieb-tech-milestones</title>

<link rel="stylesheet" href="styles.css">

<a href="https://www.cnbc.com/2018/03/27/eight-milestones-in-the-development-of-computers-and-home-technology.html">CNBC’s List of Important Events in Tech</a>

<a href="https://www.computerhistory.org/timeline/">Timeline of Computer History

<a href="https://www.britannica.com/technology/Windows-OS">History of Windows</a>

</a>

<!--5 milestones 150 words per milestone about how that event/person/invention led to devices that we still use today.-->
<!--ENIAC-->
    </head>
<body>

<h1 id="Title">key milestones in the development of computers and logical devices</h1>

<hr>

<p class="yeet">Technology has been around for as long as many of us can remember. <br> Technology has come such a far way since it began that we often forget to look<br> back at the key milestones of how it was created and improved. <br> This website will highlight some of these milestones.</p>

<hr>

<h2>ENIAC</h2>

<p>Before we had all of the technology that we have today that allows us to do almost anything we can imagine, people didn't have a good reliable way to predict the weather. In 1941, John Mauchly, presented a paper suggesting an electronic computer to do this. A year later, he drafted a proposal for ENIAC with the help of electrical engineer Presper Eckert. They did not have the funding they needed though, so they switched from weather forecasting to ballistics to gain backing from the army. Once the project was underway, Eckert became ENIAC’s head engineer. Mauchly was an idea-generator and booster. As war became increasingly technological, the U.S. Army created a Ballistic Research Laboratory in the 1930s. One of its assignments was calculating artillery shell firing tables. When World War II began, the people in the Army couldn’t keep up with the increasing demand for artillery calculations. The Ballistic Research Lab and Moore School developed ENIAC, an electronic solution to help with the calculations. ENIAC was a technological breakthrough, and it has led to to many more discoveries.</p>
<a href="https://www.computerhistory.org/revolution/birth-of-the-computer/4/80">Source</a>

<hr>

<h2>Apple's Macintosh</h2>

<p>Computer pioneers experimented with icons and pointing devices (like the mouse) decades before Apple unveiled its Macintosh in 1984. But it was the Mac that introduced the idea to the general public. The Mac’s coming out party was a mass media phenomenon, the 1984 Super Bowl. A now-legendary commercial invited viewers to reject conformity and explore a new way of computing. Apple followed its original Macintosh with varied desktop and portable models, and a companion LaserWriter printer. Macs quickly became the choice of artists and designers, reflecting its visual approach. The innovative Macintosh — Apple’s second attempt at a GUI-based personal computer, following the failure of the Lisa — was a small, self-contained personal computer with a much-improved, Alto-like graphical desktop. Graphic designers, artists and educators quickly adopted it. The Apple Macintosh was another technological advancement that helped shape the future for technology. Just think of where we would be without it, you might not be reading this right now!</p>

<a href="https://www.computerhistory.org/revolution/personal-computers/17/303">Source</a>

<hr>

<h2>Microsoft Windows</h2>

<p>In 1986, Microsoft introduced Windows 1.0, which which was similar to the Mac’s approach, although the Mac's performance was much better. After much work, and four years, Microsoft came out with Windows 3.0, which got many of the bugs out. With the help of a ten million dollar advertising campaign to get the word out, Windows 3.0 did very well. The 1995 consumer release Windows 95 fully integrated Windows and DOS and offered built-in Internet support, including the World Wide Web browser Internet Explorer. The growing dominance of PCs and Windows encouraged programmers and entrepreneurs to develop software designed for that combination. The mushrooming library of programs in turn encouraged more people to choose Windows which encouraged more companies to write programs for Windows. This impromptu software-hardware partnership became a self-perpetuating cycle of success. Windows brought many advancements to computers, and by the mid 1990s, more than 95% of computers worldwide ran Windows. </p>

<a href="https://www.computerhistory.org/revolution/personal-computers/17/303">Source</a>
<a href="https://www.britannica.com/technology/Windows-OS">Source 2</a>

<hr>

<h2>The World Wide Web</h2>

<p>At the world’s biggest physics laboratory, CERN in Switzerland, English programmer and physicist Tim Berners-Lee submitted two proposals for what became the Web. Neither was approved. He proceeded anyway. With only unofficial support from his boss and interested coworkers, he created “WorldWideWeb” on an advanced NeXT computer in 1990. It featured a server, HTML, URLs, and the first browser. That browser also functioned as an editor—like a word processor connected to the Internet – which reflected his original vision that the Web also incorporate authoring and personal organization tools. By 1989, the Internet was winning over major competitors like OSI, becoming the de facto networking standard. Within five years, the World Wide Web would similarly prevail over a dozen rival information systems—partly by virtue of its strengths, partly by incorporating rivals. The two together, the Web running over the Internet, swept the world and changed all of our lives. Can you imagine what the world would be like if it weren't for the World Wide Web?</p>

<a href="https://www.computerhistory.org/revolution/the-web/20/385">Source</a>

<hr>

<h2>Wireless Devices</h2>

<p>Making computers mobile was half the battle. Connecting them on-the-go was the other half. Early mobile computers could only communicate over regular telephone lines using modems, like their desktop cousins. When wireless networking arrived, it was a convenience for laptops, letting them move around homes or offices. But for handhelds, wireless was transformative: they merged with mobile phones to become the smartphone. Mobile wireless communication began with shipboard radio in the 1910s. Soldiers in WWII used walkie-talkies and backpack phones. Car phones and pagers came in the 1950s. Fully mobile cell phones arrived in the 1980s. But whether transmitting data or voice, the communications network was analog. Researchers working on ARPAnet pioneered digital wireless networking for both data and voice in the 1970s. ALOHAnet, Packet Radio Network, and Satellite Net were packet-switched, meaning they broke streams of data into small chunks sent independently, like letters in a postal system. Early mobile phone networks were analog. They used traditional telephone circuit-switching, where there was a connection (circuit) between caller and recipient for the duration of the call. The connection seamlessly moved from cell to cell as the phone moved. Mobile networks went digital in the 1990s, with competing standards like GSM in Europe and CDMA in the US. Voice was still circuit-switched, with packet-switched data services added later. In the 2000s, packet-switched “third generation” (3G) networks brought higher data speeds and made mobile web browsing practical.</p>

<a href="https://www.computerhistory.org/revolution/mobile-computing/18/322">Source</a>

<hr>

<h1 class="Grogu">Thank You!</h1>

<p class="bro">Thank you for reading this brief history of technology!</p>

<p class="Ayyy"> I hope you learned something!</p>

</body>

</html>